{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import zoom\n",
    "from PIL import Image\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import block_reduce\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from mesh_vox import read_and_reshape_stl, voxelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"C:\\Users\\harsh\\OneDrive\\Desktop\\GDrive\\tester_folder\"\n",
    "stl_path = r\"C:/Users/harsh/OneDrive/Desktop/GDrive/Categorized_Parts\"\n",
    "\n",
    "image = glob.glob(img_path + \"/*\" + \"/*\" + \"[!.txt]\")\n",
    "stl = glob.glob(stl_path + \"/*\" + \"/STL\" + \"/*.stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = image[:56] + image[150:206]\n",
    "stl2 = stl[:56] + stl[150:206]\n",
    "images2 = np.reshape(image2, (-1,1)).astype(np.object)\n",
    "stls2 = np.reshape(stl2, (-1,1)).astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.reshape(image, (-1,1)).astype(np.object)\n",
    "stls = np.reshape(stl, (-1,1)).astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_fn(folder):\n",
    "    folder = folder.decode('utf-8')\n",
    "    files = tf.gfile.Glob(folder + \"\\*\")\n",
    "    files = np.reshape(files, (-1,1)).astype(np.object)\n",
    "    return files\n",
    "\n",
    "def pre_dir(folder):\n",
    "    out = tf.py_func(dir_fn, [folder], Tout=tf.string)\n",
    "    return out\n",
    "\n",
    "def img_Parse(img):\n",
    "    img = img[0].decode('utf-8')\n",
    "    image = cv2.imread(img,0)/255.\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    image = np.expand_dims(image,-1)\n",
    "    image = image.astype(np.float32)\n",
    "    return image\n",
    "\n",
    "def preprocess(img):\n",
    "    out = tf.py_func(img_Parse, [img], Tout=tf.float32)\n",
    "    return out\n",
    "\n",
    "def mapping_fn(folder):\n",
    "    x = tf.map_fn(pre_dir, folder, dtype=np.object)\n",
    "    image = tf.map_fn(preprocess, x[0], dtype=tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stl_parser(stl):\n",
    "    stl = stl.decode('utf8')\n",
    "    mesh, _ = read_and_reshape_stl(stl, 16)\n",
    "    voxels, _ = voxelize(mesh, [16,16,16], False)\n",
    "    voxels = voxels.astype(np.float32)\n",
    "    return voxels\n",
    "\n",
    "def py_fun_stl(stl):\n",
    "    out = tf.py_func(stl_parser, [stl], Tout=tf.float32)\n",
    "    return out\n",
    "\n",
    "def map_fn(stl):\n",
    "    out = tf.map_fn(py_fun_stl, stl, dtype=tf.float32)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairGenerator(object):\n",
    "    \n",
    "    def __init__(self, images, stl, batch=16):\n",
    "        self.images = images\n",
    "        self.stl = stl\n",
    "        self.batch = batch\n",
    "        \n",
    "    def map_fn(self, images, stl):\n",
    "        img_files = tf.map_fn(pre_dir, images, dtype=np.object)\n",
    "        image = tf.map_fn(preprocess, img_files[0], dtype=tf.float32)\n",
    "        voxels = tf.map_fn(py_fun_stl, stl, dtype=tf.float32)\n",
    "        voxels = tf.squeeze(voxels)\n",
    "        return (image,voxels)\n",
    "    \n",
    "    def datagen(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.images, self.stl))\n",
    "        dataset = dataset.shuffle(100)\n",
    "        dataset = dataset.map(self.map_fn).batch(self.batch).repeat()\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.prefetch(self.batch)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inputs(object):\n",
    "    \n",
    "    def __init__(self, img, stl, batch=32):\n",
    "        self.img = img\n",
    "        self.stl = stl\n",
    "        self.batch = batch\n",
    "        self.iterator = 0\n",
    "        self.limit = (len(img)//batch)\n",
    "        \n",
    "    def img_parser(self,img):\n",
    "        image = cv2.imread(img,0)/255.\n",
    "        image = cv2.resize(image, (64,64))\n",
    "        image = np.expand_dims(image,-1)\n",
    "        return image\n",
    "    \n",
    "    def _image(self, img_path):\n",
    "        img_path = glob.glob(img_path + \"/*\")\n",
    "        return np.array([self.img_parser(x) for x in img_path])\n",
    "    \n",
    "    def stl_parser(self, stl):\n",
    "        mesh, _ = read_and_reshape_stl(stl, 32)\n",
    "        voxels, _ = voxelize(mesh, [32,32,32], False)\n",
    "        return voxels\n",
    "    \n",
    "    def pair_generator(self):\n",
    "        if self.iterator == self.limit:\n",
    "            self.iterator = 0\n",
    "        s, e = self.iterator, self.iterator+self.batch\n",
    "        images = self.img[s:e]\n",
    "        stls = self.stl[s:e]\n",
    "        im = np.array([self._image(i) for i in images], dtype=np.float32)\n",
    "        im = np.swapaxes(im,0,1)\n",
    "        vx = np.array([self.stl_parser(s) for s in stls], dtype=np.float32)\n",
    "        self.iterator += 1\n",
    "        return im, vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(name, shape):\n",
    "    \n",
    "    init = tf.random_normal_initializer()\n",
    "    val = tf.get_variable(name=name, shape=shape, dtype=tf.float32, initializer=init, trainable=True)\n",
    "    return val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self, prev_layer):\n",
    "        self._prev_layer = prev_layer\n",
    "        self._input_shape = prev_layer.output_shape\n",
    "        self._output = None\n",
    "        self._out_shape = None\n",
    "        self._name = None\n",
    "        \n",
    "    def set_output(self):\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        if self._out_shape is None:\n",
    "            self.set_output()\n",
    "        return self._out_shape\n",
    "    \n",
    "    @property\n",
    "    def output(self):\n",
    "        if self._output is None:\n",
    "            self.set_output()\n",
    "        return self._output\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, shape, inp=None):\n",
    "        self._input = inp\n",
    "        self._out_shape = shape\n",
    "        self._name = name\n",
    "        \n",
    "    @property\n",
    "    def output_shape(self):\n",
    "        return self._out_shape\n",
    "    \n",
    "    @property\n",
    "    def output(self):\n",
    "        return self._input\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer, filter_conf, params=None):\n",
    "        super().__init__(prev_layer)\n",
    "        self._filter_shape = [filter_conf[1], filter_conf[1], self._input_shape[-1], filter_conf[0]]\n",
    "        self._name = name\n",
    "        \n",
    "        if params is None:\n",
    "            self.W = Weights(self._name+\"W\", self._filter_shape)\n",
    "            self.b = Weights(self._name+\"b\", self._filter_shape[-1])\n",
    "        else:\n",
    "            self.W = params[0]\n",
    "            self.b = params[1]\n",
    "            \n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def set_output(self):\n",
    "        self._out_shape = [self._input_shape[0], \\\n",
    "                          self._input_shape[1] - self._filter_shape[0] + 1, \\\n",
    "                           self._input_shape[2] - self._filter_shape[1] + 1, \\\n",
    "                           self._filter_shape[-1]]\n",
    "        \n",
    "        conv = tf.nn.conv2d(input= self._prev_layer.output, filter=self.W, strides=[1,1,1,1], padding=\"VALID\")\n",
    "        self._output = conv + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer, ksize=2, strides=2):\n",
    "        super().__init__(prev_layer)\n",
    "        self.ksize = ksize\n",
    "        self.kernel = [1, ksize, ksize, 1]\n",
    "        self.strides = [1, strides, strides , 1]\n",
    "        self._name = name\n",
    "        \n",
    "    def set_output(self):\n",
    "        \n",
    "        width = self._prev_layer.output_shape[1]\n",
    "        height = self._prev_layer.output_shape[2]\n",
    "\n",
    "            \n",
    "        self._out_shape = [self._prev_layer.output_shape[0], \\\n",
    "                             (width-self.ksize)//2 + 1, (height-self.ksize)//2 + 1, \\\n",
    "                             self._prev_layer.output_shape[3]]\n",
    "        \n",
    "        self._output = tf.nn.max_pool(value=self._prev_layer.output, \\\n",
    "                                 ksize=self.kernel, strides=self.strides, \\\n",
    "                                 padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer):\n",
    "        super().__init__(prev_layer)\n",
    "        self._name = name\n",
    "        \n",
    "    def set_output(self):\n",
    "        \n",
    "        self._out_shape = [self._prev_layer.output_shape[0], \\\n",
    "                          np.prod(self._prev_layer.output_shape[1:])]\n",
    "        \n",
    "        self._output = tf.reshape(self._prev_layer.output, self._out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer, units, params=None):\n",
    "        super().__init__(prev_layer)\n",
    "        self._name = name\n",
    "        self.units = units\n",
    "        \n",
    "        if len(self._prev_layer.output_shape) != 2:\n",
    "            raise ValueError(\"Add a Flatten Layer before Dense Layer\")\n",
    "            \n",
    "        if params is None:\n",
    "            self.W = Weights(self._name+'W', [self._prev_layer.output_shape[1], self.units])\n",
    "            self.b = Weights(self._name+'b', self.units)\n",
    "        else:\n",
    "            self.W = params[0]\n",
    "            self.b = params[1]\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def set_output(self):\n",
    "        \n",
    "        self._out_shape = [self._prev_layer.output_shape[0], self.units]\n",
    "        \n",
    "        self._output = tf.matmul(a=self._prev_layer.output, b=self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTranspose(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer, filter_conf, pad=\"VALID\", params=None):\n",
    "        super().__init__(prev_layer)\n",
    "        self._name = name\n",
    "        self.n_kernel = filter_conf[0]\n",
    "        self.ksize = filter_conf[1]\n",
    "        self.pad = pad\n",
    "        self.batch, self.h, self.w, self.d, self.channels = self._prev_layer.output_shape\n",
    "        \n",
    "        if params == None:\n",
    "            self.W = Weights(self._name+\"W\", [self.ksize, self.ksize, self.ksize, self.n_kernel, \\\n",
    "                                              self._prev_layer.output_shape[-1]])\n",
    "        else:\n",
    "            self.W = params\n",
    "        self.params = self.W\n",
    "        \n",
    "        if pad==\"VALID\":\n",
    "            padding = self.ksize-1\n",
    "        else:\n",
    "            padding = 0\n",
    "            \n",
    "        self._out_shape = [self._prev_layer.output_shape[0], \\\n",
    "                          self._prev_layer.output_shape[1] + padding, \\\n",
    "                          self.w + padding, \\\n",
    "                          self.d + padding, \\\n",
    "                          self.n_kernel]\n",
    "            \n",
    "    \n",
    "    def set_output(self):\n",
    "        \n",
    "        self._output = tf.nn.conv3d_transpose(self._prev_layer.output, self.W, self._out_shape, strides=(1,1,1,1,1), padding=self.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py_func_grad(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "    \n",
    "    rndname = 'PyFuncGrad' + str(np.random.randint(0, 1E+8))\n",
    "    \n",
    "    tf.RegisterGradient(rndname)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rndname,\n",
    "                                \"PyFuncStateless\": rndname}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "    \n",
    "def UnPool(prev_out, padding, size):\n",
    "    b,h,w,d,c = prev_out.shape\n",
    "    if padding == 0:\n",
    "        padding = -h\n",
    "    pad_inp = np.zeros(shape=(b, h*size+2*padding, w*size+2*padding, d*size+2*padding, c), dtype=np.float32)\n",
    "    pad_inp[:, padding:-padding:size, padding:-padding:size, padding:-padding:size, :] = prev_out\n",
    "    return pad_inp\n",
    "\n",
    "def grad_unpool(op, grad):\n",
    "    x = op.inputs[0]\n",
    "    p,s = op.inputs[1:]\n",
    "    z = grad[:, p:-p:s, p:-p:s, p:-p:s, :]\n",
    "    return x - 0.1*z, p, s\n",
    "\n",
    "def UnPoolingFunc(prev_out, padding, size, name):\n",
    "    \n",
    "    with tf.name_scope(name, 'UnPooling', [prev_out, padding, size]) as name:\n",
    "        z = py_func_grad(UnPool, [prev_out, padding, size], [tf.float32], name=name, grad=grad_unpool)\n",
    "        return z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnPooling(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer, size, padding=None):\n",
    "        super().__init__(prev_layer)\n",
    "        self._name = name\n",
    "        self.size = size\n",
    "        self.batch, self.h, self.w, self.d, self.channels = self._prev_layer.output_shape\n",
    "        \n",
    "        if padding:\n",
    "            self.padding = padding\n",
    "            self._out_shape = [self.batch, self.h*size + 2*padding, self.w*size + 2*padding, \\\n",
    "                              self.d*size + 2*padding, self.channels]\n",
    "            self.padded_input = tf.Variable(tf.zeros(shape=self._out_shape))\n",
    "            \n",
    "        else:\n",
    "            self.padding = 0\n",
    "            self._out_shape = [self.batch, self.h*size, self.w*size, self.d*size, self.channels]\n",
    "            self.padded_input = tf.Variable(tf.zeros(shape=self._out_shape))\n",
    "        \n",
    "    def set_output(self):\n",
    "        \n",
    "        self._output = UnPoolingFunc(self._prev_layer.output, self.padding, self.size, self._name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer, act):\n",
    "        super().__init__(prev_layer)\n",
    "        self._name = name\n",
    "        self.act = act\n",
    "        self._out_shape = self._prev_layer.output_shape\n",
    "    \n",
    "    def set_output(self):\n",
    "        if self.act == \"leakyrelu\":\n",
    "            self._output = tf.nn.leaky_relu(self._prev_layer.output, alpha=0.3)\n",
    "        elif self.act == \"relu\":\n",
    "            self._output = tf.nn.relu(self._prev_layer.output)\n",
    "        elif self.act == \"sigmoid\":\n",
    "            self._output = tf.nn.sigmoid(self._prev_layer.output)\n",
    "        elif self.act == \"softmax\":\n",
    "            self._output = tf.nn.softmax(self._prev_layer.output)\n",
    "        elif self.act == 'tanh':\n",
    "            self._output = tf.nn.tanh(self._prev_layer.output)\n",
    "        else:\n",
    "            raise ValueError(\"Use a valid activation function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandLayer(Layer):\n",
    "    \n",
    "    def __init__(self, name, prev_layer):\n",
    "        super().__init__(prev_layer)\n",
    "        self._name = name\n",
    "        self._out_shape = self._prev_layer.output_shape + [1]\n",
    "        \n",
    "    def set_output(self):\n",
    "        self._output = tf.expand_dims(self._prev_layer.output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightsInitializer(object):\n",
    "    \n",
    "    def __init__(self, batch_size=16):\n",
    "        \n",
    "        self.batch = batch_size\n",
    "        self.shape = (12,self.batch,64,64,1)\n",
    "        self.prev_shape = (self.batch,3,3,3,32)\n",
    "        self.image = tf.zeros(shape=self.shape)\n",
    "        \n",
    "        self.input = InputLayer('input', self.image.shape[1:], self.image[0])\n",
    "        self.conv1 = ConvLayer('cv1', self.input, (64,5))\n",
    "        self.pool1 = PoolLayer('pl1', self.conv1, 1, 2)\n",
    "        self.conv2 = ConvLayer('cv2', self.pool1, (128,5))\n",
    "        self.pool2 = PoolLayer('pl2', self.conv2, 1, 2)\n",
    "        self.conv3 = ConvLayer('cv3', self.pool2, (256,3))\n",
    "        self.pool3 = PoolLayer('pl3', self.conv3, 1, 2)\n",
    "        self.conv4 = ConvLayer('cv4', self.pool3, (384,3))\n",
    "        self.pool4 = PoolLayer('pl4', self.conv4, 1, 2)\n",
    "        #self.conv5 = ConvLayer('cv5', self.pool4, (512,3))\n",
    "        #self.pool5 = PoolLayer('pl5', self.conv5, 1, 2)\n",
    "        \n",
    "        self.flat1 = FlattenLayer('flt1', self.pool4)\n",
    "        self.dense1 = DenseLayer('ds1', self.flat1, 512)\n",
    "        self.prev_s = InputLayer('pvs', shape=self.prev_shape, inp=tf.zeros(self.prev_shape))\n",
    "        self.rnn = RNN('rcn', self.prev_s, self.dense1)\n",
    "        self.cell = tf.nn.rnn_cell.LSTMCell(864)\n",
    "        self.deconv1 = ConvTranspose('dcv1', self.rnn, (128,3))\n",
    "        self.depool1 = UnPooling('upl1', self.deconv1, 2, 1)\n",
    "        self.deconv2 = ConvTranspose('dcv2', self.depool1, (32,3))\n",
    "        #self.depool2 = UnPooling('upl2', self.deconv2, 2, padding=1)\n",
    "        self.deconv3 = ConvTranspose('dcv3', self.deconv2, (16,3))\n",
    "        #self.depool3 = UnPooling('upl3', self.deconv3, 2, padding=1)\n",
    "        self.deconv4 = ConvTranspose('dcv4', self.deconv3, (1,1), \"SAME\")\n",
    "        #self.deconv5 = ConvTranspose('dcv5', self.deconv4, (1,1), \"SAME\")\n",
    "\n",
    "        \n",
    "def RCNN(image, W, batch):\n",
    "    \n",
    "    image = tf.transpose(image, [1,0,2,3,4])\n",
    "    def Recurrence(prev_s, curr_x):\n",
    "\n",
    "        #prev_s = InputLayer('ps', prev_s.shape, prev_s)\n",
    "        input_ = InputLayer('inp', (batch,64,64,1) ,curr_x)\n",
    "\n",
    "        conv1_ = ConvLayer('conv1', input_, (64,5), params=W.conv1.params)\n",
    "        aconv1_ = ActivationLayer('aconv1', conv1_, \"sigmoid\")\n",
    "        pool1_ = PoolLayer('pool1', aconv1_, 1, 2)\n",
    "\n",
    "        conv2_ = ConvLayer('conv2', pool1_, (128,5), params=W.conv2.params)\n",
    "        aconv2_ = ActivationLayer('aconv2', conv2_, \"sigmoid\")\n",
    "        pool2_ = PoolLayer('pool2', aconv2_, 1, 2)\n",
    "\n",
    "        conv3_ = ConvLayer('conv3', pool2_, (256,3), params=W.conv3.params)\n",
    "        aconv3_ = ActivationLayer('aconv3', conv3_, \"sigmoid\")\n",
    "        pool3_ = PoolLayer('pool3', aconv3_, 1, 2)\n",
    "        \n",
    "        conv4_ = ConvLayer('conv4', pool3_, (384,3), params=W.conv4.params)\n",
    "        aconv4_ = ActivationLayer('aconv4', conv4_, \"sigmoid\")\n",
    "        pool4_ = PoolLayer('pool4', aconv4_, 1, 2)\n",
    "        \n",
    "        #conv5_ = ConvLayer('conv5', pool4_, (512,3), params=W.conv5.params)\n",
    "        #aconv5_ = ActivationLayer('aconv5', conv5_, \"relu\")\n",
    "        #pool5_ = PoolLayer('pool5', aconv5_, 1, 2)\n",
    "\n",
    "        flat_ = FlattenLayer('flat', pool4_)\n",
    "        dense_ = DenseLayer('dense', flat_, 512, params=W.dense1.params)\n",
    "        adense_ = ActivationLayer('adense', dense_, \"sigmoid\")\n",
    "        #rnn_ = RNN('rnn', prev_s, adense_, params=W.rnn.params)\n",
    "        #afc_ = ActivationLayer('afc', rnn_, \"sigmoid\")\n",
    "\n",
    "        return adense_.output\n",
    "    \n",
    "    #prev_s = W.prev_s\n",
    "    prev_s = tf.zeros(shape=(batch, 512))\n",
    "    scn = tf.scan(Recurrence, elems = image, initializer=prev_s)\n",
    "    rnn_inputs = [tf.squeeze(i,0) for i in tf.split(scn, 12, 0)]\n",
    "    outputs, final = tf.nn.static_rnn(W.cell, rnn_inputs, dtype=tf.float32)\n",
    "    final = tf.reshape(final[-1], shape=(batch,3,3,3,32))\n",
    "    print(final.shape)\n",
    "    rnn_out = InputLayer('rnnout', (batch,3,3,3,32), final) \n",
    "    #return rnn_out\n",
    "    dconv1_ = ConvTranspose('deconv1', rnn_out, (128,3), params=W.deconv1.params)\n",
    "    dpool1_ = UnPooling('unpool1', dconv1_, 2, padding=1)\n",
    "    adpool1_ = ActivationLayer('aunpool1', dpool1_, 'sigmoid')\n",
    "\n",
    "    dconv2_ = ConvTranspose('deconv2', adpool1_, (32,3), params=W.deconv2.params)\n",
    "    #dpool2_ = UnPooling('unpool2', dconv2_, 2, padding=1)\n",
    "    adpool2_ = ActivationLayer('aunpool2', dconv2_, 'sigmoid')\n",
    "\n",
    "    dconv3_ = ConvTranspose('deconv3', adpool2_, (16,3), params=W.deconv3.params)\n",
    "    #dpool3_ = UnPooling('unpool3', dconv3_, 1, padding=1)\n",
    "    adpool3_ = ActivationLayer('aunpool3', dconv3_, 'sigmoid')\n",
    "\n",
    "    dconv4_ = ConvTranspose('deconv4', adpool3_, (1,1), \"SAME\", params=W.deconv4.params)\n",
    "    adconv4_ = ActivationLayer('adeconv4', dconv4_, 'sigmoid')\n",
    "    #dconv5_ = ConvTranspose('deconv5', adconv4_, (1,1), \"SAME\", params=W.deconv5.params)\n",
    "    #adconv5_ = ActivationLayer('adeconv5', dconv5_, 'sigmoid')\n",
    "\n",
    "    return tf.squeeze(adconv4_.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 8\n",
    "W = WeightsInitializer(batch)\n",
    "pgen = PairGenerator(images2, stls2, batch)\n",
    "it = pgen.datagen()\n",
    "next_element = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(batch,12,64,64,1))\n",
    "y = tf.placeholder(tf.float32, shape=(batch,16,16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RCNN(x, W, batch)\n",
    "cost = tf.reduce_mean(tf.losses.mean_squared_error(y, pred))\n",
    "optimizer = tf.train.AdamOptimizer(0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(100):\n",
    "    x_, y_ = sess.run(next_element)\n",
    "    opt = sess.run(optimizer, feed_dict={x: x_, y: y_})\n",
    "    loss = sess.run(cost, feed_dict={x: x_, y: y_})\n",
    "    if b%50==0:\n",
    "        print('Iteration: {} \\nLoss: {}\\n'.format(b, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = sess.run(pred, feed_dict={x: x_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.gca(projection='3d')\n",
    "ax.voxels(y_[0], edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.gca(projection='3d')\n",
    "ax.voxels(pd[7]>0.5, edgecolor='k')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
